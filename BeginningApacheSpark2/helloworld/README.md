# Resilient Distributed Datasets  弹性分布式数据集

RDD 既代表了spark中的大规模数据处理方式，而且还抽象的表示了数据的处理操作。

RDD一旦定义，是不可修改的、容错的、并行数据结构。



## Immutable 不可修改的

RDD被设计为不可变的，这意味着您不能特别地修改由RDD表示的数据集中的特定行。

你可以调用RDD的一些可用的操作来处理RDD的行，但是这会返回一个新的RDD。那么之前的基础的RDD仍然是不变的。而返回的新的RDD则包含了你想要使用的数据。



## Fault Tolerant 容错

并行处理多种数据集通常需要一个机器的集群来管理和执行计算逻辑。如果这些机器集群中有一台或者多台出现了故障，那么势必会影响整个的数据处理工作。RDD会自动的在后台检测和管理故障的机器节点，一旦发现有问题的节点，spark会自动的重新构建节点。



## Parallel Data Structures 并行的数据结构

对于一个非常庞大的文件，比如 1TB 的日志文件，要找到里面的文字含有“exception”这个单词，如果只是简单的用线性的方式来处理，势必会很慢。

更好的方式是，将这个1TB的文件拆分为多个块来执行上述的逻辑，这就是并行的方式。这样做显然会成倍的提升处理的效率，缩短得到结果等待的时间。每一个块都含有一个若干行的集合。

每一个块的集合都含有这样的数据结构，它包含所有行的集合，而且可以便利这些行。



## In-Memory Computing 在内存中运行

spark和Hadoop中的MapReduce最大的不同就在于，spark对数据的处理是在内存中运行的，而MapReduce则需要与磁盘进行多次的I/O操作。



## Data Partitioning and Placement 数据的拆分和放置

将庞大的数据进行拆分后，数据库位于什么集群中的什么位置就变得非常重要。而且为了提高数据处理的效率，一般会根据数据处理的任务，将有关的数据都放在同一个节点进行处理，这样显然能提高数据分析处理的效率，减少数据在集群中节点之间的I/O。

而且有了这些数据拆分和放置的信息，RDD就能够自如的管理这些集群中节点来执行计算逻辑。



## Rich Set of Operations 丰富的数据操作

RDD提供了丰富的数据处理操作的方法（API），比如数据转换、过滤分组、拼接、聚合、排序和统计。

需要注意的一点是，这些数据操作不是细粒度的，而是针对许多行进行的，不是针对某一个特定行。



# RDD 的操作

RDD的操作分为两个类型，一个是 transformations，另一个是 actions。

transformation操作是延迟执行的，transformation只是定义了数据的转换逻辑，当action操作执行时，才会触发transformation对数据进行真正的转换处理。































